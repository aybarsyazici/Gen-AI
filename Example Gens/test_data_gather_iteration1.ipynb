{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"#f0c6c6\">Generating examples for testing</font></h3>\n",
    "\n",
    "<font color=\"#a5adcb\"> We have the following prompts, each for GPT3.5 and GPT4 </font>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. <font color=\"#b7bdf8\"> Fewshot (helper.prompt_few_shot) </font> \n",
    "2. <font color=\"#b7bdf8\"> Oneshot (helper.prompt_gpt_3) </font> \n",
    "3. <font color=\"#b7bdf8\"> Oneshot First try (helper.prompt_gpt) </font>\n",
    "4. <font color=\"#b7bdf8\"> Oneshot short (helper.prompt_gpt_short) </font>\n",
    "5. <font color=\"#b7bdf8\"> Oneshot short extra info (helper.prompt_gpt_short_extra_info) </font>\n",
    "6. <font color=\"#b7bdf8\"> Oneshot extrainfo (helper.prompt_gpt_3_extra_info) </font>\n",
    "\n",
    "---\n",
    "\n",
    "<p color=\"#a5adcb\"\"><font color=\"#a5adcb\"> Few shot examples are good examples generated by GPT4 | TODO: Generate examples by removing already fulfilled rules.\n",
    "\n",
    "Extra info signifies that the rules don't have to be in order.\n",
    "\n",
    "Short prompt is the previous prompt shortened. Hoping to test if longer or shorter prompts generate better examples.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load rule data\n",
      "Rule data loaded...\n",
      "\n",
      "Starting rule extraction...\n",
      "\t -> Starting to sort rules by lift\n",
      "\t -> Done sorting rules...\n",
      "______________________________\n",
      "\t -> Starting RegEx pattern creation\n",
      "\t -> Done creating RegEx patterns...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import helper \n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "DATA_DIR = '../dataset'\n",
    "\n",
    "rules, to_be_joined, extracted_rules = helper.load_required_data(DATA_DIR)\n",
    "\n",
    "# sample random 100 recipes from the dataset under dataset/full_dataset.csv\n",
    "seed = 1010\n",
    "sample_recipes = pd.read_csv(f'{DATA_DIR}/full_dataset.csv').sample(100, random_state=seed)\n",
    "sample_recipes['directions'] = sample_recipes['directions'].apply(lambda x: eval(x))\n",
    "# drop recipes that have directions with less than 125 characters in total\n",
    "sample_recipes['directions_length'] = sample_recipes['directions'].apply(lambda x: len(' '.join(x)))\n",
    "sample_recipes = sample_recipes[sample_recipes['directions_length'] > 125]\n",
    "\n",
    "sample_recipes['preprocessed'] = sample_recipes['directions'].apply(lambda x: preprocess_string(' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab 8 examples from the middle of the dataset\n",
    "recipes_to_test = sample_recipes.iloc[45:53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_few_shot,\n",
    "    model=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df to store results\n",
    "few_shot_gpt4_results_df = pd.DataFrame(few_shot_gpt4_results)\n",
    "# to csv\n",
    "few_shot_gpt4_results_df.to_csv(f'{DATA_DIR}/few_shot_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_few_shot,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df to store results\n",
    "few_shot_gpt3_results_df = pd.DataFrame(few_shot_gpt3_results)\n",
    "# to csv\n",
    "few_shot_gpt3_results_df.to_csv(f'{DATA_DIR}/few_shot_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_3,\n",
    "    model=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_gpt4_results_df = pd.DataFrame(one_shot_gpt4_results)\n",
    "one_shot_gpt4_results_df.to_csv(f'{DATA_DIR}/one_shot_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_3,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_gpt3_results_df = pd.DataFrame(one_shot_gpt3_results)\n",
    "one_shot_gpt3_results_df.to_csv(f'{DATA_DIR}/one_shot_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_first_try_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper._print_response(one_shot_first_try_gpt3_results[2]['new_recipe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_first_try_gpt3_results_df = pd.DataFrame(one_shot_first_try_gpt3_results)\n",
    "one_shot_first_try_gpt3_results_df.to_csv(f'{DATA_DIR}/one_shot_first_try_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_first_try_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt,\n",
    "    model=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_first_try_gpt4_results_df = pd.DataFrame(one_shot_first_try_gpt4_results)\n",
    "one_shot_first_try_gpt4_results_df.to_csv(f'{DATA_DIR}/one_shot_first_try_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_short,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_gpt3_results_df = pd.DataFrame(one_shot_short_gpt3_results)\n",
    "one_shot_short_gpt3_results_df.to_csv(f'{DATA_DIR}/one_shot_short_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_short,\n",
    "    model=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_gpt4_results_df = pd.DataFrame(one_shot_short_gpt4_results)\n",
    "one_shot_short_gpt4_results_df.to_csv(f'{DATA_DIR}/one_shot_short_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_extra_info_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_short_extra_info,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_extra_info_gpt3_results_df = pd.DataFrame(one_shot_short_extra_info_gpt3_results)\n",
    "one_shot_short_extra_info_gpt3_results_df.to_csv(f'{DATA_DIR}/one_shot_short_extra_info_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_extra_info_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_short_extra_info,\n",
    "    model=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_short_extra_info_gpt4_results_df = pd.DataFrame(one_shot_short_extra_info_gpt4_results)\n",
    "one_shot_short_extra_info_gpt4_results_df.to_csv(f'{DATA_DIR}/one_shot_short_extra_info_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_extra_info_gpt4_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_3_extra_info,\n",
    "    model=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_extra_info_gpt4_results_df = pd.DataFrame(one_shot_extra_info_gpt4_results)\n",
    "one_shot_extra_info_gpt4_results_df.to_csv(f'{DATA_DIR}/one_shot_extra_info_gpt4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_extra_info_gpt3_results = helper.pipeline_chunk(\n",
    "    recipes_to_test,\n",
    "    extracted_rules,\n",
    "    helper.prompt_gpt_3_extra_info,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_extra_info_gpt3_results_df = pd.DataFrame(one_shot_extra_info_gpt3_results)\n",
    "one_shot_extra_info_gpt3_results_df.to_csv(f'{DATA_DIR}/one_shot_extra_info_gpt3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
